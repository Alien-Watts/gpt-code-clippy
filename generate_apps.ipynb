{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b529017-a33e-4b2d-be5b-387ae7dd51e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-07-18 07:38:07.042553: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2021-07-18 07:38:07.042596: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53610604-dff1-4a65-83b5-0795d5b3b473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration formatted-d9019fd8ed858445\n",
      "Reusing dataset apps (/home/shared/.cache/hf/datasets/apps/formatted-d9019fd8ed858445/0.1.0/5987476458cc986e36654364319c6fe798b880d64a35518cbc00dc04f3c41e4d)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_dataset(\"/home/arto/datasets/datasets/apps/apps.py\", \"formatted\", split=\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3811070c-c6a0-4a84-9362-cf7de0d5bd75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = AutoModelForCausalLM.from_pretrained(\"/home/arto/gpt-code-clippy-lr1e-4-bs1024-f/ckpt-80000\",from_flax=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EleutherAI/gpt-neo-125M\")\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "830a374f-a70d-466d-a766-3671e5c11765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id :\n",
      "\n",
      "6386\n",
      "==========\n",
      "question :\n",
      "\n",
      "\n",
      "QUESTION:\n",
      "Given an array arr.  You can choose a set of integers and remove all the occurrences of these integers in the array.\n",
      "Return the minimum size of the set so that at least half of the integers of the array are removed.\n",
      " \n",
      "Example 1:\n",
      "Input: arr = [3,3,3,3,5,5,5,2,2,7]\n",
      "Output: 2\n",
      "Explanation: Choosing {3,7} will make the new array [5,5,5,2,2] which has size 5 (i.e equal to half of the size of the old array).\n",
      "Possible sets of size 2 are {3,5},{3,2},{5,2}.\n",
      "Choosing set {2,7} is not possible as it will make the new array [3,3,3,3,5,5,5] which has size greater than half of the size of the old array.\n",
      "\n",
      "Example 2:\n",
      "Input: arr = [7,7,7,7,7,7]\n",
      "Output: 1\n",
      "Explanation: The only possible set you can choose is {7}. This will make the new array empty.\n",
      "\n",
      "Example 3:\n",
      "Input: arr = [1,9]\n",
      "Output: 1\n",
      "\n",
      "Example 4:\n",
      "Input: arr = [1000,1000,3,7]\n",
      "Output: 1\n",
      "\n",
      "Example 5:\n",
      "Input: arr = [1,2,3,4,5,6,7,8,9,10]\n",
      "Output: 5\n",
      "\n",
      " \n",
      "Constraints:\n",
      "\n",
      "1 <= arr.length <= 10^5\n",
      "arr.length is even.\n",
      "1 <= arr[i] <= 10^5\n",
      "class Solution:\n",
      "    def minSetSize(self, arr: List[int]) -> int:\n",
      "        \n",
      "\n",
      "Use Call-Based format\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "==========\n",
      "answer :\n",
      "\n",
      "class Solution:\n",
      "\tdef minSetSize(self, arr: List[int]) -> int:\n",
      "\t\t# get length of array \n",
      "\t\tlength = len(arr)\n",
      "\t\t# build dict to count how many times each int appears\n",
      "\t\tcounts = {}\n",
      "\t\tfor num in arr:\n",
      "\t\t\tif num not in counts:\n",
      "\t\t\t\tcounts[num] =1\n",
      "\t\t\telse:\n",
      "\t\t\t\tcounts[num] += 1\n",
      "\t\t\t\t\n",
      "\t\t# print(counts)\n",
      "\t\t\n",
      "\t\t# get values from dict, sort in descending order\n",
      "\t\tdescending = sorted(counts.values(), reverse =  True)\n",
      "\t\t# print(descending)\n",
      "\t\t# initialize 2 variables: count and total\n",
      "\t\tcount = 0\n",
      "\t\ttotal = 0\n",
      "\t\t# loop over descending list of counts\n",
      "\t\tfor num in descending:\n",
      "\t\t\t# add each number to our total\n",
      "\t\t\ttotal += num\n",
      "\t\t\t# increment count by 1\n",
      "\t\t\tcount += 1\n",
      "\t\t\t# if our total is half or more, return count\n",
      "\t\t\tif total >= length/2:\n",
      "\t\t\t\treturn count\n",
      "\n",
      "==========\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "id = random.randint(0, len(dataset)-1)\n",
    "sample = dataset[id]\n",
    "\n",
    "for k, v in sample.items():\n",
    "    print(k, \":\\n\")\n",
    "    print(v)\n",
    "    print(\"=\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1b109cec-c721-410f-b3df-38a50ae8607b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = dataset[82239][\"question\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "820f8729-a368-4b41-91ff-56601d21aaaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~~~\n",
      "~~~\n",
      "~~~[\n",
      "  [1, 2, 3, 4, 5, 6],       # smallest number is 1\n",
      "  [4, 5, 6],                # largest number is 1\n",
      "  [18, 17, 19, 20, 21, 22], # smallest number is 18\n",
      "]\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "~~~\n",
      "\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "start = len(input_ids[0])\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=1000,\n",
    "    do_sample=True,\n",
    "    top_p=0.95,\n",
    ")\n",
    "\n",
    "print(tokenizer.decode(output[0][start:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee80ebdb-163c-43b8-b1cb-0585d013bba1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
