{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84b1a438-cf1d-402e-a56f-2c4f9dd5ad51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, FlaxGPTNeoForCausalLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7d50cd18-33ed-4b67-82ad-5c48eb9a9b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ckpt = 'EleutherAI/gpt-neo-125M'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "065c03c3-2e4a-4f20-a30d-25ada1418b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57ed89aae89749aba08b715ec2258b82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
    "model = FlaxGPTNeoForCausalLM.from_pretrained(model_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2f9fb26-2e26-4f57-aa93-e349475203f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "75c0c2f6-47ad-41c3-8c66-a1ceeecde061",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "class Model(nn.Module):\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "666977a1-de0d-4900-bf61-ae2b672e51bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(prompt, return_tensors='jax')\n",
    "input_ids = inputs.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "249e4a8a-7a7e-4e8b-83be-7184a4c0dd0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 19, 50257)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs = model(**inputs)\n",
    "outputs.logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "eee873f5-073c-4cbe-8b15-114ea18b2de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DeviceArray([[  198, 11748, 28034,   198,  6738, 28034,  1330,   299,\n",
       "                 77,   198,   198,  4871,  9104,     7, 20471,    13,\n",
       "              26796,  2599,   198]], dtype=int32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "82666225-3ab7-405f-9536-4e9e3085be24",
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model.generate(input_ids,\n",
    "                     max_length=200, \n",
    "#                      num_beams=5,\n",
    "                     pad_token_id = tokenizer.pad_token_id\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6cc862b-23ef-417d-ae83-1b2eafb0460f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FlaxGreedySearchOutput(sequences=DeviceArray([[  198, 11748, 28034,   198,  6738, 28034,  1330,   299,\n",
       "                 77,   198,   198,  4871,  9104,     7, 20471,    13,\n",
       "              26796,  2599,   198,   220,   220,   220,   825, 11593,\n",
       "              15003,   834,     7,   944,    11,  1438,    11,  2746,\n",
       "                 11, 12429, 46265, 22046,  2599,   198,   220,   220,\n",
       "                220,   220,   220,   220,   220,  2208,     7, 17633,\n",
       "                 11,  2116,   737,   834, 15003,   834,     7,  3672,\n",
       "                 11,  2746,    11, 12429, 46265, 22046,     8,   198,\n",
       "                220,   220,   220,   220,   220,   220,   220,  2116,\n",
       "                 13,  3672,   796,  1438,   198,   220,   220,   220,\n",
       "                220,   220,   220,   220,  2116,    13, 19849,   796,\n",
       "               2746,   198,   220,   220,   220,   220,   220,   220,\n",
       "                220,  2116,    13, 46265, 22046,   796,   479,    86,\n",
       "              22046,   198,   220,   220,   220,   220,   220,   220,\n",
       "                220,  2116,    13,  3672,    62, 40290,   796,   705,\n",
       "              19849,     6,   198,   220,   220,   220,   220,   220,\n",
       "                220,   220,  2116,    13,  3672,    62, 37333,   844,\n",
       "                796,   705, 19849,    62,  3672,     6,   198,   220,\n",
       "                220,   220,   220,   220,   220,   220,  2116,    13,\n",
       "               3672,    62, 40290,    62, 40290,   796,   705, 19849,\n",
       "                 62,  3672,    62, 40290,     6,   198,   220,   220,\n",
       "                220,   220,   220,   220,   220,  2116,    13,  3672,\n",
       "                 62, 37333,   844,    62, 40290,   796,   705, 19849,\n",
       "                 62,  3672,    62, 37333,   844,     6,   198,   220,\n",
       "                220,   220,   220,   220,   220,   220,  2116,    13]],            dtype=int32))"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8f6c746a-2d56-4da4-acb5-e066a6a230f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "import torch\n",
      "from torch import nn\n",
      "\n",
      "class Model(nn.Module):\n",
      "    def __init__(self, name, model, **kwargs):\n",
      "        super(Model, self).__init__(name, model, **kwargs)\n",
      "        self.name = name\n",
      "        self.model = model\n",
      "        self.kwargs = kwargs\n",
      "        self.name_prefix ='model'\n",
      "        self.name_suffix ='model_name'\n",
      "        self.name_prefix_prefix ='model_name_prefix'\n",
      "        self.name_suffix_prefix ='model_name_suffix'\n",
      "        self.\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(out[0][0]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
